{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_speaker_names(x):\n",
    "    if x == 'Vice President Joe Biden':\n",
    "        return 'Joe Biden'\n",
    "    elif x == 'President Donald J. Trump':\n",
    "        return 'Donald Trump'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def add_hour(x):\n",
    "    temp = x.split(':')\n",
    "    if len(temp) == 2:\n",
    "        x = f'00:{x}'\n",
    "    return x\n",
    "\n",
    "def overflow(x):\n",
    "    hour, minute, second = x['hour'], x['minute'], x['second']\n",
    "    if second >= 60:\n",
    "        minute += (second // 60)\n",
    "        second = second % 60\n",
    "    if minute >= 60:\n",
    "        hour = (minute // 60)\n",
    "        minute = minute % 60\n",
    "    return hour, minute, second\n",
    "\n",
    "def underflow(x):\n",
    "    hour, minute, second = x['hour'], x['minute'], x['second']\n",
    "    if second < 0:\n",
    "        minute -= abs(second // 60)\n",
    "        second = abs(second % 60)\n",
    "    if minute < 0:\n",
    "        hour = abs(minute // 60)\n",
    "        minute = abs(minute % 60)\n",
    "    return hour, minute, second\n",
    "\n",
    "def convert_time(x):\n",
    "    hour, minute, second = x['hour'], x['minute'], x['second']\n",
    "    hour = str(hour)\n",
    "    minute = str(minute)\n",
    "    second = str(second)\n",
    "    return f'{hour.zfill(2)}:{minute.zfill(2)}:{second.zfill(2)}'\n",
    "        \n",
    "def time_in_seconds(x):\n",
    "    return 3600 * x['hour'] + 60 * x['minute'] + x['second']\n",
    "\n",
    "def format_time(x):\n",
    "    hour = str(int(x // 3600))\n",
    "    x = x % 3600\n",
    "    minute = str(int(x // 60))\n",
    "    x = x % 60\n",
    "    second = str(int(x))\n",
    "    return f'{hour.zfill(2)}:{minute.zfill(2)}:{second.zfill(2)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 12 0.25\n",
      "68.0\n"
     ]
    }
   ],
   "source": [
    "debate1 = pd.read_csv('./data/kaggle_debate/us_election_2020_1st_presidential_debate.csv', dtype={'speaker' : str, 'minute' : str, 'text' : str})\n",
    "debate2 = pd.read_csv('./data/kaggle_debate/us_election_2020_2nd_presidential_debate.csv', dtype={'speaker' : str, 'minute' : str, 'text' : str})\n",
    "debate_vp = pd.read_csv('./data/kaggle_debate/us_election_2020_vice_presidential_debate.csv', dtype={'speaker' : str, 'minute' : str, 'text' : str})\n",
    "\n",
    "# A little preprocessing\n",
    "####################################\n",
    "## Debate #1\n",
    "debate1['time'] = debate1['minute']\n",
    "debate1['time'] = debate1['time'].apply(add_hour)\n",
    "debate1['second'] = debate1['time'].apply(lambda x: int(x.split(':')[2]))\n",
    "debate1['minute'] = debate1['time'].apply(lambda x: int(x.split(':')[1]))\n",
    "debate1['hour'] = debate1['time'].apply(lambda x: int(x.split(':')[0]))\n",
    "debate1 = debate1[['speaker', 'time', 'hour', 'minute', 'second', 'text']]\n",
    "\n",
    "# Change speaker names\n",
    "debate1['speaker'] = debate1['speaker'].apply(change_speaker_names)\n",
    "\n",
    "# Fixes timing issues (of resets)\n",
    "hour, minute, second = debate1.iloc[[178]][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate1.iloc[179:]['hour'] = debate1.iloc[179:]['hour'] + hour\n",
    "debate1.iloc[179:]['minute'] = debate1.iloc[179:]['minute'] + minute\n",
    "debate1.iloc[179:]['second'] = debate1.iloc[179:]['second'] + second\n",
    "\n",
    "# Fixes potential overflow\n",
    "temp = debate1.iloc[179:][['hour', 'minute', 'second']].apply(overflow, axis=1).apply(pd.Series)\n",
    "debate1.iloc[179:]['hour'] = temp[0]\n",
    "debate1.iloc[179:]['minute'] = temp[1]\n",
    "debate1.iloc[179:]['second'] = temp[2]\n",
    "\n",
    "# Shift everything so we start at 00:00\n",
    "hour, minute, second = debate1.iloc[0][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate1['hour'] = debate1['hour'] - hour\n",
    "debate1['minute'] = debate1['minute'] - minute\n",
    "debate1['second'] = debate1['second'] - second\n",
    "\n",
    "# Fixes potential underflow\n",
    "temp = debate1[['hour', 'minute', 'second']].apply(underflow, axis=1).apply(pd.Series)\n",
    "debate1['hour'] = temp[0]\n",
    "debate1['minute'] = temp[1]\n",
    "debate1['second'] = temp[2]\n",
    "\n",
    "# Fix overall time\n",
    "debate1['time'] = debate1[['hour', 'minute', 'second']].apply(convert_time, axis=1)\n",
    "debate1['time_seconds'] = debate1[['hour', 'minute', 'second']].apply(time_in_seconds, axis=1)\n",
    "\n",
    "####################################\n",
    "## Debate #2\n",
    "debate2['time'] = debate2['minute']\n",
    "debate2['time'] = debate2['time'].apply(add_hour)\n",
    "debate2['second'] = debate2['time'].apply(lambda x: int(x.split(':')[2]))\n",
    "debate2['minute'] = debate2['time'].apply(lambda x: int(x.split(':')[1]))\n",
    "debate2['hour'] = debate2['time'].apply(lambda x: int(x.split(':')[0]))\n",
    "debate2 = debate2[['speaker', 'time', 'hour', 'minute', 'second', 'text']]\n",
    "\n",
    "# Fixes first timing issue (of resets)\n",
    "hour, minute, second = debate2.iloc[[88]][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate2.iloc[89:337]['hour'] = debate2.iloc[89:337]['hour'] + hour\n",
    "debate2.iloc[89:337]['minute'] = debate2.iloc[89:337]['minute'] + minute\n",
    "debate2.iloc[89:337]['second'] = debate2.iloc[89:337]['second'] + second\n",
    "debate2.iloc[89:337]\n",
    "\n",
    "# Fixes potential overflow\n",
    "temp = debate2.iloc[89:337][['hour', 'minute', 'second']].apply(overflow, axis=1).apply(pd.Series)\n",
    "debate2.iloc[89:337]['hour'] = temp[0]\n",
    "debate2.iloc[89:337]['minute'] = temp[1]\n",
    "debate2.iloc[89:337]['second'] = temp[2]\n",
    "\n",
    "# Fixes first timing issue (of resets)\n",
    "hour, minute, second = debate2.iloc[[336]][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate2.iloc[337:]['hour'] = debate2.iloc[337:]['hour'] + hour\n",
    "debate2.iloc[337:]['minute'] = debate2.iloc[337:]['minute'] + minute\n",
    "debate2.iloc[337:]['second'] = debate2.iloc[337:]['second'] + second\n",
    "\n",
    "# Fixes potential overflow\n",
    "temp = debate2.iloc[337:][['hour', 'minute', 'second']].apply(overflow, axis=1).apply(pd.Series)\n",
    "debate2.iloc[337:]['hour'] = temp[0]\n",
    "debate2.iloc[337:]['minute'] = temp[1]\n",
    "debate2.iloc[337:]['second'] = temp[2]\n",
    "\n",
    "# Shift everything so we start at 00:00\n",
    "hour, minute, second = debate2.iloc[0][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate2['hour'] = debate2['hour'] - hour\n",
    "debate2['minute'] = debate2['minute'] - minute\n",
    "debate2['second'] = debate2['second'] - second\n",
    "\n",
    "# Fixes potential underflow\n",
    "temp = debate2[['hour', 'minute', 'second']].apply(underflow, axis=1).apply(pd.Series)\n",
    "debate2['hour'] = temp[0]\n",
    "debate2['minute'] = temp[1]\n",
    "debate2['second'] = temp[2]\n",
    "\n",
    "# Fix overall time\n",
    "debate2['time'] = debate2[['hour', 'minute', 'second']].apply(convert_time, axis=1)\n",
    "debate2['time_seconds'] = debate2[['hour', 'minute', 'second']].apply(time_in_seconds, axis=1)\n",
    "\n",
    "####################################\n",
    "## Debate VP\n",
    "debate_vp['time'] = debate_vp['minute']\n",
    "debate_vp['time'] = debate_vp['time'].apply(add_hour)\n",
    "debate_vp['second'] = debate_vp['time'].apply(lambda x: int(x.split(':')[2]))\n",
    "debate_vp['minute'] = debate_vp['time'].apply(lambda x: int(x.split(':')[1]))\n",
    "debate_vp['hour'] = debate_vp['time'].apply(lambda x: int(x.split(':')[0]))\n",
    "debate_vp = debate_vp[['speaker', 'time', 'hour', 'minute', 'second', 'text']]\n",
    "\n",
    "# Adjust the reset to 00:00\n",
    "hour, minute, second = debate_vp.iloc[[135]][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate_vp.iloc[135:]['hour'] = debate_vp.iloc[135:]['hour'] - hour\n",
    "debate_vp.iloc[135:]['minute'] = debate_vp.iloc[135:]['minute'] - minute\n",
    "debate_vp.iloc[135:]['second'] = debate_vp.iloc[135:]['second'] - second\n",
    "\n",
    "# Fixes potential underflow\n",
    "temp = debate_vp.iloc[135:][['hour', 'minute', 'second']].apply(underflow, axis=1).apply(pd.Series)\n",
    "debate_vp.iloc[135:]['hour'] = temp[0]\n",
    "debate_vp.iloc[135:]['minute'] = temp[1]\n",
    "debate_vp.iloc[135:]['second'] = temp[2]\n",
    "\n",
    "# Fixes first timing issue (of resets)\n",
    "hour, minute, second = debate_vp.iloc[[134]][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate_vp.iloc[135:]['hour'] = debate_vp.iloc[135:]['hour'] + hour\n",
    "debate_vp.iloc[135:]['minute'] = debate_vp.iloc[135:]['minute'] + minute\n",
    "debate_vp.iloc[135:]['second'] = debate_vp.iloc[135:]['second'] + second\n",
    "debate_vp.iloc[135:]\n",
    "\n",
    "# Fixes potential overflow\n",
    "temp = debate_vp.iloc[135:][['hour', 'minute', 'second']].apply(overflow, axis=1).apply(pd.Series)\n",
    "debate_vp.iloc[135:]['hour'] = temp[0]\n",
    "debate_vp.iloc[135:]['minute'] = temp[1]\n",
    "debate_vp.iloc[135:]['second'] = temp[2]\n",
    "\n",
    "# Shift everything so we start at 00:00\n",
    "hour, minute, second = debate_vp.iloc[0][['hour', 'minute', 'second']].to_numpy().squeeze().astype(int)\n",
    "debate_vp['hour'] = debate_vp['hour'] - hour\n",
    "debate_vp['minute'] = debate_vp['minute'] - minute\n",
    "debate_vp['second'] = debate_vp['second'] - second\n",
    "\n",
    "# Fixes potential underflow\n",
    "temp = debate_vp[['hour', 'minute', 'second']].apply(underflow, axis=1).apply(pd.Series)\n",
    "debate_vp['hour'] = temp[0]\n",
    "debate_vp['minute'] = temp[1]\n",
    "debate_vp['second'] = temp[2]\n",
    "\n",
    "# Fix overall time\n",
    "debate_vp['time'] = debate_vp[['hour', 'minute', 'second']].apply(convert_time, axis=1)\n",
    "debate_vp['time_seconds'] = debate_vp[['hour', 'minute', 'second']].apply(time_in_seconds, axis=1)\n",
    "\n",
    "vectorized_format_time = np.vectorize(format_time)\n",
    "\n",
    "low, high = debate1['time_seconds'].iloc[[0, -1]].to_numpy()\n",
    "seconds, step_size = np.linspace(low, high, num=90, retstep=True)\n",
    "seconds = seconds.round()\n",
    "index_to_seconds = {}\n",
    "for i, second in enumerate(seconds):\n",
    "    index_to_seconds[i] = second\n",
    "times = vectorized_format_time(seconds)\n",
    "\n",
    "joe = debate1[debate1['speaker'] == 'Joe Biden']\n",
    "\n",
    "parsed = joe[(joe['time_seconds'] >= 200) & (joe['time_seconds'] <= 600)]\n",
    "\n",
    "text = parsed['text']\n",
    "text = ' '.join(text)\n",
    "text = re.sub(r'[^\\w\\s]','',text).lower()\n",
    "\n",
    "custom_remove_string = ['the', 'is', 'of', 'that', 'to']\n",
    "text = text.split()\n",
    "text = np.array([w for w in text if w not in custom_remove_string])\n",
    "words, frequencies = np.unique(text, return_counts=True)\n",
    "\n",
    "hist = {}\n",
    "for word, frequency in zip(words, frequencies):\n",
    "    hist[word] = frequency\n",
    "    \n",
    "import math\n",
    "\n",
    "low = 11.25\n",
    "high = 29.5\n",
    "\n",
    "low_low = math.floor(low)\n",
    "low_high = math.ceil(low)\n",
    "low_dec = low - low_low\n",
    "\n",
    "high_low = math.floor(high)\n",
    "high_high = math.ceil(high)\n",
    "high_dec = high - high_low\n",
    "\n",
    "print(low_low, low_high, low_dec)\n",
    "print(65 + low_dec*(77-65))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['covid', 'us']\n",
    "pytrends.build_payload(keyword_list, cat=0, timeframe='2020-01-01 2020-12-08', geo='US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid</th>\n",
       "      <th>us</th>\n",
       "      <th>isPartial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-12</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-19</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-26</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-09</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-23</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-08</th>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-15</th>\n",
       "      <td>78</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-22</th>\n",
       "      <td>94</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-29</th>\n",
       "      <td>94</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-05</th>\n",
       "      <td>84</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-12</th>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-19</th>\n",
       "      <td>62</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>57</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-03</th>\n",
       "      <td>53</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10</th>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-24</th>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-31</th>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-07</th>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-14</th>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-21</th>\n",
       "      <td>68</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-28</th>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-05</th>\n",
       "      <td>77</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-12</th>\n",
       "      <td>83</td>\n",
       "      <td>32</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-19</th>\n",
       "      <td>71</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-26</th>\n",
       "      <td>69</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-02</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-09</th>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-16</th>\n",
       "      <td>49</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-23</th>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-30</th>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-06</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-13</th>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-20</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-27</th>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-04</th>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-11</th>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18</th>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25</th>\n",
       "      <td>57</td>\n",
       "      <td>38</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-08</th>\n",
       "      <td>79</td>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-15</th>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-22</th>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-29</th>\n",
       "      <td>78</td>\n",
       "      <td>33</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-06</th>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            covid  us isPartial\n",
       "date                           \n",
       "2020-01-05      0  33     False\n",
       "2020-01-12      0  26     False\n",
       "2020-01-19      0  27     False\n",
       "2020-01-26      0  29     False\n",
       "2020-02-02      0  28     False\n",
       "2020-02-09      0  27     False\n",
       "2020-02-16      0  28     False\n",
       "2020-02-23      2  32     False\n",
       "2020-03-01      7  35     False\n",
       "2020-03-08     30  47     False\n",
       "2020-03-15     78  57     False\n",
       "2020-03-22     94  52     False\n",
       "2020-03-29     94  46     False\n",
       "2020-04-05     84  40     False\n",
       "2020-04-12     65  38     False\n",
       "2020-04-19     62  34     False\n",
       "2020-04-26     57  34     False\n",
       "2020-05-03     53  34     False\n",
       "2020-05-10     53  32     False\n",
       "2020-05-17     51  30     False\n",
       "2020-05-24     45  31     False\n",
       "2020-05-31     37  32     False\n",
       "2020-06-07     42  31     False\n",
       "2020-06-14     52  35     False\n",
       "2020-06-21     68  37     False\n",
       "2020-06-28     76  35     False\n",
       "2020-07-05     77  35     False\n",
       "2020-07-12     83  32     False\n",
       "2020-07-19     71  31     False\n",
       "2020-07-26     69  31     False\n",
       "2020-08-02     60  30     False\n",
       "2020-08-09     55  30     False\n",
       "2020-08-16     49  28     False\n",
       "2020-08-23     45  28     False\n",
       "2020-08-30     48  34     False\n",
       "2020-09-06     41  41     False\n",
       "2020-09-13     40  43     False\n",
       "2020-09-20     42  41     False\n",
       "2020-09-27     54  39     False\n",
       "2020-10-04     55  38     False\n",
       "2020-10-11     48  36     False\n",
       "2020-10-18     52  38     False\n",
       "2020-10-25     57  38     False\n",
       "2020-11-01     48  72     False\n",
       "2020-11-08     79  41     False\n",
       "2020-11-15    100  36     False\n",
       "2020-11-22     78  31     False\n",
       "2020-11-29     78  33     False\n",
       "2020-12-06     78  31      True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytrends.interest_over_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "The request failed: Google returned a response with code 400.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bce06182e96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfile_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' \\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkeyword_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2020-01-01 2020-12-08'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'US'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeyword_list_dataframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mkeyword_list_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytrends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterest_over_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/general/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36mbuild_payload\u001b[0;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_payload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'req'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# get tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/general/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;34m\"\"\"Makes request to Google to get API tokens for interest over time, interest by region and related queries\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# make the request and parse the returned json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         widget_dict = self._get_data(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGENERAL_URL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrendReq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_METHOD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/general/lib/python3.8/site-packages/pytrends/request.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             raise exceptions.ResponseError(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0;34m'The request failed: Google returned a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;34m'response with code {0}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResponseError\u001b[0m: The request failed: Google returned a response with code 400."
     ]
    }
   ],
   "source": [
    "related_words_dir = './data/google_trends/'\n",
    "keyword_list_dataframe = None\n",
    "for topic_file in os.listdir(related_words_dir):\n",
    "    topic_file_path = f'{related_words_dir}{topic_file}'\n",
    "    with open(topic_file_path, 'r') as f:\n",
    "        file_contents = f.readlines()\n",
    "        file_contents = [content.strip(' \\n') for content in file_contents]\n",
    "    for keyword_list in chunker(file_contents, 1):\n",
    "        pytrends.build_payload(keyword_list, cat=0, timeframe='2020-01-01 2020-12-08', geo='US')\n",
    "        if keyword_list_dataframe is None:\n",
    "            keyword_list_dataframe = pytrends.interest_over_time()\n",
    "        else:\n",
    "            keyword_list_dataframe = pd.concat([keyword_list_dataframe, pytrends.interest_over_time()], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in keyword_list_dataframe.columns:\n",
    "    if i != 'isPartial':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words_dir = './data/google_trends/'\n",
    "word_to_subwords = {}\n",
    "for topic_file in os.listdir(related_words_dir):\n",
    "    topic_file_path = f'{related_words_dir}{topic_file}'\n",
    "    with open(topic_file_path, 'r') as f:\n",
    "        file_contents = f.readlines()\n",
    "        file_contents = [content.strip(' \\n') for content in file_contents]\n",
    "    word_to_subwords[topic_file.split('-')[0]] = file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list_dataframe[word_to_subwords['education']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, subwords in word_to_subwords.items():\n",
    "    word_dataframe = keyword_list_dataframe[subwords]\n",
    "    word_dataframe.to_csv(f'./data/google_trends/{word}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
